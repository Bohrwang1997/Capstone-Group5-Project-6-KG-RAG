{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c2f6c08-9ef7-4069-b32b-068867ef6933",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch transformers langchain faiss-cpu\n",
    "!pip install -U langchain-community sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2bb8297-adf3-4679-bf01-ff4465025a3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import necessary tookets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a243d47-f00d-4020-806e-08c2edc2fa75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df.sample(1000)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_questions = train_df['question'].tolist()\n",
    "train_sql_queries = train_df['sql'].tolist()\n",
    "val_questions = val_df['question'].tolist()\n",
    "val_sql_queries = val_df['sql'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "061121f9-619d-4032-bd4d-3603af446e53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# setup the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "train_tokenized_inputs = tokenizer.batch_encode_plus(train_questions, padding=True, truncation=True, return_tensors='pt')\n",
    "train_tokenized_outputs = tokenizer.batch_encode_plus(train_sql_queries, padding=True, truncation=True, return_tensors='pt')\n",
    "val_tokenized_inputs = tokenizer.batch_encode_plus(val_questions, padding=True, truncation=True, return_tensors='pt')\n",
    "val_tokenized_outputs = tokenizer.batch_encode_plus(val_sql_queries, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "073cef55-7717-4223-896f-478a704434b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set up the preprocessing\n",
    "class SQLOnlineDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs, tokenized_outputs):\n",
    "        self.input_ids = tokenized_inputs['input_ids']\n",
    "        self.attention_mask = tokenized_inputs['attention_mask']\n",
    "        self.labels = tokenized_outputs['input_ids']\n",
    "        self.decoder_attention_mask = tokenized_outputs['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'decoder_attention_mask': self.decoder_attention_mask[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = SQLOnlineDataset(train_tokenized_inputs, train_tokenized_outputs)\n",
    "val_dataset = SQLOnlineDataset(val_tokenized_inputs, val_tokenized_outputs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccb8bab6-3d33-4755-afe8-dbd423ac82e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "302b495f-a451-4bf8-aea5-c026565ced1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                decoder_attention_mask=decoder_attention_mask,\n",
    "                return_dict=True\n",
    "            )\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21531baa-191b-4cef-878f-68c33f7ba89a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'sql_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6ef593a-493c-41f4-a148-fa4a4e0e7098",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# open the model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.load_state_dict(torch.load('sql_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cb247f6-9a05-4b17-85f8-d4de54fd5e0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialize the tokenizert\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# sample question\n",
    "new_question = \"What team has more than 49 laps and a grid of 8?\"\n",
    "input_ids = tokenizer.encode(new_question, return_tensors='pt')\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=150,\n",
    "    num_beams=5,\n",
    "    early_stopping=True,\n",
    "    length_penalty=1.0\n",
    ")\n",
    "sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# print out the result\n",
    "print(f\"Question: {new_question}\")\n",
    "print(f\"Generated SQL query: {sql_query}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Text 2 sql",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
